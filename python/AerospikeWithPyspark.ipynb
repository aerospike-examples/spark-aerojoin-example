{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spark and Aerospike using pyspark\n",
    "\n",
    "\n",
    "findspark setup needed for jupyter requires pip install findspark.\n",
    "If only using pyspark shell can skip\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import aerospike\n",
    "import findspark\n",
    "findspark.init()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In Jupyter findspark.init() must be called before the import of pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "from pyspark.context import SparkContext\n",
    "from pyspark.sql.context import SQLContext\n",
    "from pyspark.sql.session import SparkSession\n",
    "from pyspark.sql.types import LongType, StringType, StructField, StructType\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set up spark and point at locally running aerospike on default port."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = SparkContext.getOrCreate()\n",
    "spark = SparkSession(sc)\n",
    "sqlContext = SQLContext(sc)\n",
    "\n",
    "spark.conf.set(\"aerospike.namespace\", \"test\")\n",
    "spark.conf.set(\"aerospike.seedhost\", \"localhost\")\n",
    "spark.conf.set(\"aerospike.port\", \"3000\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 1\n",
    "\n",
    "Simple example writing raw data usign the client and loading/querying"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Writing test data using embedded client\")\n",
    "config = {\"hosts\": [(\"127.0.0.1\", 3000)]}\n",
    "\n",
    "try:\n",
    "    client = aerospike.client(config).connect()\n",
    "except Exception as e:\n",
    "    import sys\n",
    "    print(\"failed to connect to the cluster with\", config[\"hosts\"], str(e))\n",
    "    sys.exit(1)\n",
    "\n",
    "for num in range(10):\n",
    "    key = (\"test\", \"spark-test\", \"spark-test\" + str(num))\n",
    "    print(str(key))\n",
    "    client.put(key, {\"one\": num, \"two\": \"two_\" + str(num), \"three\": num})\n",
    "\n",
    "print(\"Loading test data to dataframe\")\n",
    "thingsDF = (\n",
    "    spark.read.format(\"com.aerospike.spark.sql\")\n",
    "    .option(\"aerospike.set\", \"spark-test\")\n",
    "    .load()\n",
    ")\n",
    "\n",
    "print(\"All test data\")\n",
    "thingsDF.show()\n",
    "\n",
    "print(\"Filtering test data\")\n",
    "thingsDF.registerTempTable(\"things\")\n",
    "filteredThings = spark.sql(\"select * from things where one = 5\")\n",
    "print(\"Just thing number 5\")\n",
    "filteredThings.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 2\n",
    "\n",
    "Example making use of schemas to save dataframes as well as queries and operations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rows = [\n",
    "    (\"Bill_Malcolm\", \"Bill\", \"Malcolm\", 1975, \"Indie\"),\n",
    "    (\"James_Bob\", \"James\", \"Bob\", 1983, \"Rep\"),\n",
    "    (\"Martin_Paul\", \"Martin\", \"Paul\", 1991, \"Dem\"),\n",
    "    (\"Smith_John\", \"Smith\", \"John\", 1996, \"Indie\"),\n",
    "    (\"Smallberries_Kevin\", \"Smallberries\", \"Kevin\", 2007, \"Dem\"),\n",
    "    (\"Kohl_Jen\", \"Kohl\", \"Jen\", 2009, \"Indie\"),\n",
    "    (\"Prichard_Julia\", \"Prichard\", \"Julia\", 2010, \"Rep\"),\n",
    "    (\"Williams_Tony\", \"Williams\", \"Tony\", 2013, \"Indie\"),\n",
    "    (\"Babka_Malcom\", \"Babka\", \"Malcom\", 2015, \"Rep\"),\n",
    "]\n",
    "\n",
    "schema = StructType(\n",
    "    [\n",
    "        StructField(\"key\", StringType(), True),\n",
    "        StructField(\"last\", StringType(), True),\n",
    "        StructField(\"first\", StringType(), True),\n",
    "        StructField(\"bornDate\", LongType(), True),\n",
    "        StructField(\"party\", StringType(), True),\n",
    "    ]\n",
    ")\n",
    "inputRDD = sc.parallelize(rows)\n",
    "newDF = sqlContext.createDataFrame(inputRDD, schema)\n",
    "\n",
    "(\n",
    "    newDF.write.mode(\"overwrite\")\n",
    "    .format(\"com.aerospike.spark.sql\")\n",
    "    .option(\"aerospike.set\", \"people\")\n",
    "    .option(\"aerospike.updateByKey\", \"key\")\n",
    "    .save()\n",
    ")\n",
    "\n",
    "peopleDF = (\n",
    "    sqlContext.read.format(\"com.aerospike.spark.sql\")\n",
    "    .option(\"aerospike.set\", \"people\")\n",
    "    .load()\n",
    ")\n",
    "peopleDF.createOrReplaceTempView(\"people\")\n",
    "\n",
    "print(\"All voters\")\n",
    "peopleDF.show()\n",
    "print(\"Voter parties\")\n",
    "peopleDF.groupBy(\"party\").count().show()\n",
    "\n",
    "print(\"Independent voters of legal age\")\n",
    "voterDF = spark.sql('SELECT * FROM people WHERE bornDate < 2001 AND party = \"Indie\"')\n",
    "voterDF.show()\n",
    "\n",
    "print(\"Writing filtered voters to independent_voters set\")\n",
    "(\n",
    "    voterDF.write.mode(\"overwrite\")\n",
    "    .format(\"com.aerospike.spark.sql\")\n",
    "    .option(\"aerospike.set\", \"independent_voters\")\n",
    "    .option(\"aerospike.updateByKey\", \"key\")\n",
    "    .save()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see the filtered data from the Aerospike aql tool:\n",
    "\n",
    "\n",
    "```\n",
    "aql> select * from test.independent_voters\n",
    "+----------+-----------+----------------+---------+---------+\n",
    "| bornDate | first     | key            | last    | party   |\n",
    "+----------+-----------+----------------+---------+---------+\n",
    "| 1975     | \"Malcolm\" | \"Bill_Malcolm\" | \"Bill\"  | \"Indie\" |\n",
    "| 1996     | \"John\"    | \"Smith_John\"   | \"Smith\" | \"Indie\" |\n",
    "+----------+-----------+----------------+---------+---------+\n",
    "2 rows in set (0.054 secs)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "sc.stop()\n",
    "print(\"Done\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
